import { NewsItem } from '@/types'

interface AiBotNewsItem {
  title: string
  content: string
  url: string
  publishTime: string
  category: string
  source: string
}

class NewsCrawler {
  private corsProxy = 'https://api.allorigins.win/get?url='
  
  async crawlAiBotNews(): Promise<NewsItem[]> {
    try {
      const url = 'https://ai-bot.cn/daily-ai-news/'
      const proxyUrl = `${this.corsProxy}${encodeURIComponent(url)}`
      
      console.log('ğŸ•·ï¸ å¼€å§‹çˆ¬å–AIå·¥å…·é›†æ–°é—»æ•°æ®...')
      
      const response = await fetch(proxyUrl)
      const data = await response.json()
      const htmlContent = data.contents
      
      // è§£æHTMLå†…å®¹
      const parser = new DOMParser()
      const doc = parser.parseFromString(htmlContent, 'text/html')
      
      const newsItems: NewsItem[] = []
      
      // æŸ¥æ‰¾æ–°é—»åˆ—è¡¨å®¹å™¨
      const newsElements = doc.querySelectorAll('.news-item, .daily-news-item, article, .post-item')
      
      newsElements.forEach((element, index) => {
        try {
          const titleElement = element.querySelector('h1, h2, h3, .title, .news-title')
          const contentElement = element.querySelector('.content, .excerpt, .summary, p')
          const linkElement = element.querySelector('a')
          const timeElement = element.querySelector('.time, .date, time, .publish-time')
          
          const title = titleElement?.textContent?.trim()
          const content = contentElement?.textContent?.trim()
          const url = linkElement?.getAttribute('href')
          const timeText = timeElement?.textContent?.trim()
          
          if (title && title.length > 10) {
            const newsItem: NewsItem = {
              id: `aibot-${Date.now()}-${index}`,
              title,
              content: content || title,
              summary: content ? content.substring(0, 100) + '...' : title,
              source: 'AIå·¥å…·é›†',
              url: url ? (url.startsWith('http') ? url : `https://ai-bot.cn${url}`) : undefined,
              publishTime: this.parseTime(timeText || ''),
              tags: this.extractTags(title, content || ''),
              category: this.categorizeNews(title, content || ''),
              readTime: Math.ceil((content || title).length / 200),
            }
            
            newsItems.push(newsItem)
          }
        } catch (error) {
          console.warn('è§£ææ–°é—»é¡¹å¤±è´¥:', error)
        }
      })
      
      // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
      if (newsItems.length === 0) {
        const alternativeElements = doc.querySelectorAll('div[class*="news"], div[class*="post"], div[class*="item"], li')
        
        alternativeElements.forEach((element, index) => {
          try {
            const text = element.textContent?.trim()
            if (text && text.length > 20 && text.length < 500) {
              // ç®€å•çš„æ ‡é¢˜æå–
              const sentences = text.split(/[ã€‚ï¼ï¼Ÿ\n]/)
              const title = sentences[0]?.trim()
              
              if (title && title.length > 10) {
                const newsItem: NewsItem = {
                  id: `aibot-alt-${Date.now()}-${index}`,
                  title,
                  content: text,
                  summary: text.substring(0, 100) + '...',
                  source: 'AIå·¥å…·é›†',
                  publishTime: new Date().toISOString(),
                  tags: this.extractTags(title, text),
                  category: this.categorizeNews(title, text),
                  readTime: Math.ceil(text.length / 200),
                }
                
                newsItems.push(newsItem)
              }
            }
          } catch (error) {
            console.warn('è§£æå¤‡é€‰æ–°é—»é¡¹å¤±è´¥:', error)
          }
        })
      }
      
      console.log(`âœ… æˆåŠŸçˆ¬å– ${newsItems.length} æ¡æ–°é—»`)
      return newsItems.slice(0, 20) // é™åˆ¶è¿”å›æ•°é‡
      
    } catch (error) {
      console.error('âŒ çˆ¬å–AIå·¥å…·é›†æ–°é—»å¤±è´¥:', error)
      return []
    }
  }
  
  private parseTime(timeText: string): string {
    if (!timeText) return new Date().toISOString()
    
    const now = new Date()
    
    // å¤„ç†ç›¸å¯¹æ—¶é—´
    if (timeText.includes('åˆ†é’Ÿå‰')) {
      const minutes = parseInt(timeText.match(/(\d+)åˆ†é’Ÿå‰/)?.[1] || '0')
      return new Date(now.getTime() - minutes * 60 * 1000).toISOString()
    }
    
    if (timeText.includes('å°æ—¶å‰')) {
      const hours = parseInt(timeText.match(/(\d+)å°æ—¶å‰/)?.[1] || '0')
      return new Date(now.getTime() - hours * 60 * 60 * 1000).toISOString()
    }
    
    if (timeText.includes('å¤©å‰')) {
      const days = parseInt(timeText.match(/(\d+)å¤©å‰/)?.[1] || '0')
      return new Date(now.getTime() - days * 24 * 60 * 60 * 1000).toISOString()
    }
    
    // å¤„ç†å…·ä½“æ—¥æœŸ
    const dateMatch = timeText.match(/(\d{4})-(\d{1,2})-(\d{1,2})/)
    if (dateMatch) {
      const [, year, month, day] = dateMatch
      return new Date(parseInt(year), parseInt(month) - 1, parseInt(day)).toISOString()
    }
    
    // é»˜è®¤è¿”å›å½“å‰æ—¶é—´
    return new Date().toISOString()
  }
  
  private extractTags(title: string, content: string): string[] {
    const text = (title + ' ' + content).toLowerCase()
    const tags: string[] = []
    
    const tagKeywords = [
      { keyword: ['openai', 'gpt', 'chatgpt'], tag: 'OpenAI' },
      { keyword: ['google', 'gemini', 'bard'], tag: 'Google' },
      { keyword: ['microsoft', 'copilot'], tag: 'Microsoft' },
      { keyword: ['meta', 'llama'], tag: 'Meta' },
      { keyword: ['anthropic', 'claude'], tag: 'Anthropic' },
      { keyword: ['nvidia', 'è‹±ä¼Ÿè¾¾'], tag: 'NVIDIA' },
      { keyword: ['apple', 'è‹¹æœ'], tag: 'Apple' },
      { keyword: ['ç™¾åº¦', 'baidu'], tag: 'ç™¾åº¦' },
      { keyword: ['é˜¿é‡Œ', 'alibaba'], tag: 'é˜¿é‡Œå·´å·´' },
      { keyword: ['è…¾è®¯', 'tencent'], tag: 'è…¾è®¯' },
      { keyword: ['å­—èŠ‚', 'bytedance'], tag: 'å­—èŠ‚è·³åŠ¨' },
      { keyword: ['èèµ„', 'æŠ•èµ„'], tag: 'èèµ„' },
      { keyword: ['å¼€æº', 'open source'], tag: 'å¼€æº' },
      { keyword: ['æ¨¡å‹', 'model'], tag: 'å¤§æ¨¡å‹' },
      { keyword: ['ai', 'äººå·¥æ™ºèƒ½'], tag: 'AI' },
    ]
    
    tagKeywords.forEach(({ keyword, tag }) => {
      if (keyword.some(k => text.includes(k))) {
        tags.push(tag)
      }
    })
    
    return [...new Set(tags)].slice(0, 5)
  }
  
  private categorizeNews(title: string, content: string): string {
    const text = (title + ' ' + content).toLowerCase()
    
    if (text.includes('èèµ„') || text.includes('æŠ•èµ„') || text.includes('äº¿ç¾å…ƒ') || text.includes('è½®èèµ„')) {
      return 'æŠ•èèµ„'
    }
    
    if (text.includes('å¼€æº') || text.includes('github') || text.includes('å¼€æ”¾') || text.includes('å…è´¹')) {
      return 'å¼€æºé¡¹ç›®'
    }
    
    if (text.includes('å‘å¸ƒ') || text.includes('æ¨å‡º') || text.includes('ä¸Šçº¿') || text.includes('æ›´æ–°')) {
      return 'äº§å“å‘å¸ƒ'
    }
    
    if (text.includes('ç ”ç©¶') || text.includes('è®ºæ–‡') || text.includes('å®éªŒ') || text.includes('æµ‹è¯•')) {
      return 'æŠ€æœ¯ç ”ç©¶'
    }
    
    if (text.includes('åˆä½œ') || text.includes('æ”¶è´­') || text.includes('æˆ˜ç•¥') || text.includes('å¸‚åœº')) {
      return 'è¡Œä¸šåŠ¨æ€'
    }
    
    return 'ç»¼åˆèµ„è®¯'
  }
}

export const newsCrawler = new NewsCrawler()
export default newsCrawler